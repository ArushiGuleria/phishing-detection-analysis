# -*- coding: utf-8 -*-
"""url_ml_dl.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1zGn4OnYsR9L-q3n6zIzQmylCyev8goxJ
"""

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics import accuracy_score, classification_report
from nltk.tokenize import word_tokenize
from nltk.corpus import stopwords
from nltk.stem import PorterStemmer
from sklearn.linear_model import LinearRegression, LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.svm import SVC
from sklearn.naive_bayes import MultinomialNB
from sklearn.neighbors import KNeighborsClassifier
from sklearn.cluster import KMeans
from sklearn.ensemble import RandomForestClassifier
from scipy.sparse import hstack
import nltk
nltk.download('punkt')
nltk.download('stopwords')
nltk.download('punkt_tab')

import kagglehub

# Download latest version
path = kagglehub.dataset_download("guchiopara/look-before-you-leap")

print("Path to dataset files:", path)

import os

for filename in os.listdir(path):
    print(filename)
    if filename.endswith(".xlsx"):  # Or any other file extension if needed
        dataset_filepath = os.path.join(path, filename)

url_dataset_path = f'{path}/URL.xlsx'
html_dataset_path = f'{path}/html.xlsx'

url_df = pd.read_excel(url_dataset_path)

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt


# distribution of target
target = url_df['Category']

plt.figure(figsize=(10, 6))
ax = sns.countplot(x=target, palette='viridis')

# Add count values
for p in ax.patches:
    ax.annotate(f'{p.get_height()}', (p.get_x() + p.get_width() / 2., p.get_height()),
                ha='center', va='center', xytext=(0, 10), textcoords='offset points')

plt.title('Distribution of Target Variable')
plt.xlabel('Category')
plt.ylabel('Count')
plt.xticks(rotation=45)
plt.show()

target = url_df['Category']

# occurrences of each category
category_counts = target.value_counts()


colors = plt.cm.get_cmap('tab20', len(category_counts)).colors

# pie chart
plt.figure(figsize=(10, 8))
plt.pie(category_counts, labels=category_counts.index, autopct='%1.1f%%', startangle=140, colors=colors)
plt.title('Distribution of Target Variable')
plt.axis('equal')  # Equal aspect ratio ensures the pie is drawn as a circle.
plt.show()

url_df.head()

url_df.tail()

class TokenizerUtility:
    def __init__(self):
        self.stop_words = set(stopwords.words('english'))
        self.stemmer = PorterStemmer()

    def tokenize_and_stem(self, text):
        tokens = word_tokenize(text)
        tokens = [self.stemmer.stem(token) for token in tokens if token.isalnum()]
        tokens = [token for token in tokens if token not in self.stop_words]
        return tokens

url_X = url_df['Data'].astype(str)
from sklearn.preprocessing import LabelEncoder

y = url_df['Category']

url_X_train, url_X_test, y_train, y_test = train_test_split(
    url_X, y, test_size=0.2, random_state=42
)

tokenizer_utility = TokenizerUtility()

# Use TF-IDF vectorization
url_tfidf_vectorizer = TfidfVectorizer(tokenizer=tokenizer_utility.tokenize_and_stem, max_features=5000)
url_X_train_tfidf = url_tfidf_vectorizer.fit_transform(url_X_train)
url_X_test_tfidf = url_tfidf_vectorizer.transform(url_X_test)
print(url_X_test_tfidf.todense())

from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import precision_recall_fscore_support, accuracy_score
from time import time


train_start_time = time()

# Random Forest Classifier
rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)
rf_classifier.fit(url_X_train_tfidf, y_train)

# recording training time
train_end_time = time()

# training time
training_time = train_end_time - train_start_time
print(f"Training Time: {training_time:.2f} seconds")

# recording testing time
test_start_time = time()

# test set predictions
y_pred = rf_classifier.predict(url_X_test_tfidf)

# End testing time
test_end_time = time()

# testing time
testing_time = test_end_time - test_start_time
print(f"Testing Time: {testing_time:.2f} seconds")

# Calculate accuracy
accuracy = accuracy_score(y_test, y_pred)

# Calculate precision, recall, F1-score, false positive rate
precision, recall, f1_score, _ = precision_recall_fscore_support(y_test, y_pred, average='micro')
fpr = 1 - recall

# overall evaluation metrics
print("\nOverall Evaluation:")
print(f"Precision (Micro): {precision:.4f}")
print(f"Recall (Micro): {recall:.4f}")
print(f"F1-Score (Micro): {f1_score:.4f}")
print(f"False Positive Rate (FPR): {fpr:.4f}")
print(f"Accuracy: {accuracy:.4f}")

y_pred = rf_classifier.predict(url_X_test_tfidf)
from sklearn.metrics import roc_auc_score

accuracy = accuracy_score(y_test, y_pred)
print(f"Accuracy of random classifier: {accuracy:.4f}")

start_time = time()
dt_classifier = DecisionTreeClassifier(random_state=42)
dt_classifier.fit(url_X_train_tfidf, y_train)
end_time = time()

# training time
training_time = end_time - start_time
print(f"Training Time: {training_time:.2f} seconds")
# Make predictions on the test set using Decision Tree
test_start_time = time()
y_pred_dt = dt_classifier.predict(url_X_test_tfidf)
test_end_time = time()

# testing time
testing_time = test_end_time - test_start_time
print(f"Testing Time: {testing_time:.2f} seconds")
precision, recall, f1_score, _ = precision_recall_fscore_support(y_test, y_pred_dt, average='micro')
fpr = 1 - recall

# evaluation metrics
print("\nOverall Evaluation:")
print(f"Precision (Micro): {precision:.4f}")
print(f"Recall (Micro): {recall:.4f}")
print(f"F1-Score (Micro): {f1_score:.4f}")
print(f"False Positive Rate (FPR): {fpr:.4f}")

accuracy = accuracy_score(y_test, y_pred_dt)


print(f"Accuracy: {accuracy:.4f}")

from time import time
from sklearn.metrics import precision_recall_fscore_support
start_time = time()
svm_classifier = SVC(kernel='linear', random_state=42)
svm_classifier.fit(url_X_train_tfidf, y_train)
end_time = time()
# Make predictions on the test set using SVM


# training time
training_time = end_time - start_time
print(f"Training Time: {training_time:.2f} seconds")
test_start_time = time()
y_pred_svm = svm_classifier.predict(url_X_test_tfidf)
test_end_time = time()
testing_time = test_end_time - test_start_time
print(f"Testing Time: {testing_time:.2f} seconds")

precision, recall, f1_score, _ = precision_recall_fscore_support(y_test, y_pred_svm, average='micro')
fpr = 1 - recall

# evaluation metrics
print("\nOverall Evaluation:")
print(f"Precision (Micro): {precision:.4f}")
print(f"Recall (Micro): {recall:.4f}")
print(f"F1-Score (Micro): {f1_score:.4f}")
print(f"False Positive Rate (FPR): {fpr:.4f}")

accuracy = accuracy_score(y_test, y_pred_svm)
print(f"Accuracy: {accuracy:.4f}")

start_time = time()
nb_classifier = MultinomialNB()
nb_classifier.fit(url_X_train_tfidf, y_train)
end_time = time()

training_time = end_time - start_time
print(f"Training Time: {training_time:.2f} seconds")
test_start_time = time()
y_pred_nb = nb_classifier.predict(url_X_test_tfidf)
test_end_time = time()
testing_time = test_end_time - test_start_time
print(f"Testing Time: {testing_time:.4f} seconds")
precision, recall, f1_score, _ = precision_recall_fscore_support(y_test, y_pred_nb, average='micro')
fpr = 1 - recall

# evaluation metrics
print("\nOverall Evaluation:")
print(f"Precision (Micro): {precision:.4f}")
print(f"Recall (Micro): {recall:.4f}")
print(f"F1-Score (Micro): {f1_score:.4f}")
print(f"False Positive Rate (FPR): {fpr:.4f}")

accuracy = accuracy_score(y_test, y_pred_nb)
print(f"Accuracy: {accuracy:.4f}")

import time
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.svm import SVC
from sklearn.naive_bayes import MultinomialNB
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import precision_recall_fscore_support, accuracy_score
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split
import pandas as pd


classifiers = {

    'Logistic Regression': LogisticRegression(max_iter=1000, random_state=42),
    'K-Nearest Neighbors': KNeighborsClassifier(n_neighbors=5),
    'Gradient Boosting': GradientBoostingClassifier(n_estimators=100, random_state=42),
    'AdaBoost': AdaBoostClassifier(n_estimators=100, random_state=42)
}

# Train and evaluate each classifier
for name, clf in classifiers.items():
    print(f"\n{name}")

    # Training
    train_start_time = time.time()
    clf.fit(url_X_train_tfidf, y_train)
    train_end_time = time.time()
    training_time = train_end_time - train_start_time
    print(f"Training Time: {training_time:.2f} seconds")

    # Testing
    test_start_time = time.time()
    y_pred = clf.predict(url_X_test_tfidf)
    test_end_time = time.time()
    testing_time = test_end_time - test_start_time
    print(f"Testing Time: {testing_time:.2f} seconds")

    # Accuracy
    accuracy = accuracy_score(y_test, y_pred)
    print(f"Accuracy: {accuracy:.4f}")

    # Precision, Recall, F1-Score, False Positive Rate
    precision, recall, f1_score, _ = precision_recall_fscore_support(y_test, y_pred, average='micro')
    fpr = 1 - recall

    print(f"Precision (Micro): {precision:.4f}")
    print(f"Recall (Micro): {recall:.4f}")
    print(f"F1-Score (Micro): {f1_score:.4f}")
    print(f"False Positive Rate (FPR): {fpr:.4f}")

dt_classifier = DecisionTreeClassifier(random_state=42)
dt_classifier.fit(url_X_train_tfidf, y_train)

# predictions on the test set using Decision Tree
y_pred_dt = dt_classifier.predict(url_X_test_tfidf)

# Support Vector Machine
svm_classifier = SVC(kernel='linear', random_state=42)
svm_classifier.fit(url_X_train_tfidf, y_train)

# predictions on the test set using SVM
y_pred_svm = svm_classifier.predict(url_X_test_tfidf)
nb_classifier = MultinomialNB()
nb_classifier.fit(url_X_train_tfidf, y_train)

# predictions on the test set using Naive Bayes
y_pred_nb = nb_classifier.predict(url_X_test_tfidf)

# k-Nearest Neighbors classifier
knn_classifier = KNeighborsClassifier()
knn_classifier.fit(url_X_train_tfidf, y_train)


accuracy_dt = accuracy_score(y_test, y_pred_dt)
print(f"Decision Tree Accuracy: {accuracy_dt:.4f}")

accuracy_svm = accuracy_score(y_test, y_pred_svm)
print(f"SVM Accuracy: {accuracy_svm:.4f}")

accuracy_nb = accuracy_score(y_test, y_pred_nb)
print(f"Naive Bayes Accuracy: {accuracy_nb:.4f}")

import matplotlib.pyplot as plt

# Collect accuracies in a dictionary
accuracies = {
    "Random Forest": accuracy_score(y_test, rf_classifier.predict(url_X_test_tfidf)),
    "Decision Tree": accuracy_dt,
    "SVM": accuracy_svm,
    "Naive Bayes": accuracy_nb,

}

# classifier names and accuracies as separate lists
classifier_names = list(accuracies.keys())
classifier_accuracies = list(accuracies.values())

# bar chart
plt.figure(figsize=(8, 6))  # Adjust figure size as desired
plt.bar(classifier_names, classifier_accuracies, color=['blue', 'green', 'red', 'purple'])
plt.xlabel("Classifiers")
plt.ylabel("Accuracy")
plt.title("Comparison of Classifier Accuracies")

# data labels
for i, v in enumerate(classifier_accuracies):
    plt.text(i, v + 0.01, f"{v:.2f}", ha='center', va='bottom', fontsize=10)

plt.xticks(rotation=45)  # Rotate x-axis labels for better readability if needed
plt.tight_layout()
plt.show()

from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error

from sklearn.preprocessing import LabelEncoder

# Encode target variable labels
encoder = LabelEncoder()
y_train_encoded = encoder.fit_transform(y_train)
y_test_encoded = encoder.transform(y_test)
model = RandomForestRegressor(n_estimators=100, random_state=42)
model.fit(url_X_train_tfidf, y_train_encoded)

y_pred = model.predict(url_X_test_tfidf)

# mean squared error
accuracy = accuracy_score(y_test_encoded, y_pred.round())  # Round predictions to nearest integer
print("Accuracy:", accuracy)

from sklearn.preprocessing import LabelEncoder
from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
knn_model = KNeighborsClassifier(n_neighbors=5)  # Adjust 'n_neighbors' as needed
knn_model.fit(url_X_train_tfidf, y_train_encoded)

# predictions on the test set
y_pred = knn_model.predict(url_X_test_tfidf)

# accuracy
accuracy = accuracy_score(y_test_encoded, y_pred)
print("Accuracy:", accuracy)

from sklearn.preprocessing import LabelEncoder
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score

logistic_model = LogisticRegression(solver='lbfgs', multi_class='multinomial')
logistic_model.fit(url_X_train_tfidf, y_train_encoded)

# predictions on the test set
y_pred = logistic_model.predict(url_X_test_tfidf)

# accuracy
accuracy = accuracy_score(y_test_encoded, y_pred)
print("Accuracy:", accuracy)

from sklearn.ensemble import GradientBoostingClassifier
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
gbc_model = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, random_state=42)
gbc_model.fit(url_X_train_tfidf, y_train_encoded)

# predictions on the test set
y_pred = gbc_model.predict(url_X_test_tfidf)

# accuracy
accuracy = accuracy_score(y_test_encoded, y_pred)
print("Accuracy:", accuracy)

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv1D, MaxPooling1D, Embedding, Flatten, Dense
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
import numpy as np
from tensorflow.keras.initializers import Constant
from sklearn.preprocessing import LabelEncoder
import time
start_time = time.time()
# Assuming url_df is your DataFrame containing 'Data' and 'Category' columns
url_text = url_df['Data'].tolist()
y = url_df['Category']

# Label encoding for target variable
encoder = LabelEncoder()
y_encoded = encoder.fit_transform(y)

# Tokenizer
tokenizer = Tokenizer(num_words=5000)  # Adjust num_words as needed
tokenizer.fit_on_texts(url_text)
url_sequences = tokenizer.texts_to_sequences(url_text)

# Pad sequences to a fixed length
max_len = 100  # Adjust max_len as needed
url_padded = pad_sequences(url_sequences, maxlen=max_len, padding='post')

data_padded_train, data_padded_test, y_train, y_test = train_test_split(url_padded, y_encoded, test_size=0.2, random_state=42)

# Embedding layer
embedding_dim = 128  # Adjust embedding_dim as needed
embedding_matrix = np.random.rand(len(tokenizer.word_index) + 1, embedding_dim)  # Initialize randomly

# CNN model
model = Sequential()
model.add(Embedding(len(tokenizer.word_index) + 1, embedding_dim, input_length=max_len, embeddings_initializer=Constant(embedding_matrix)))  # Use pre-trained embeddings if available
model.add(Conv1D(32, kernel_size=3, activation='relu'))
model.add(MaxPooling1D(pool_size=2))
model.add(Flatten())
model.add(Dense(128, activation='relu'))
model.add(Dense(len(encoder.classes_), activation='softmax'))  # Output layer with number of classes

# Compile
model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

# Train
history = model.fit(data_padded_train, y_train, epochs=10, batch_size=128, validation_split=0.2)

# training and validation accuracy
end_time = time.time()
training_time = end_time - start_time
print("Training time: {:.2f} seconds".format(training_time))

# testing
test_start_time = time.time()
test_loss, test_accuracy = model.evaluate(data_padded_test, y_test)
test_end_time=time.time();
test=test_end_time-test_start_time
print(f"test_time: {test:.2f}")
print(f"Test Loss: {test_loss:.4f}")
print(f"Test Accuracy: {test_accuracy:.4f}")


# validation accuracy
validation_accuracy = history.history['val_accuracy']
print(f"Validation Accuracy: {validation_accuracy[-1]:.4f}")

print("Training time: {:.2f} seconds".format(training_time))
test_loss, test_accuracy = model.evaluate(data_padded_test, y_test)
print(f"Test Loss: {test_loss:.4f}")
print(f"Test Accuracy: {test_accuracy:.4f}")

# predictions on test set
y_pred = np.argmax(model.predict(data_padded_test), axis=-1)  # Predict class labels

# precision, recall, F1-score, and FPR for all classes
precision, recall, f1_score, _ = precision_recall_fscore_support(y_test, y_pred, average='micro')
fpr = 1 - recall

# evaluation metrics
print("\nOverall Evaluation:")
print(f"Precision (Micro): {precision:.4f}")
print(f"Recall (Micro): {recall:.4f}")
print(f"F1-Score (Micro): {f1_score:.4f}")
print(f"False Positive Rate (FPR): {fpr:.4f}")

# training time

from sklearn.metrics import precision_recall_fscore_support
y_pred = np.argmax(model.predict(data_padded_test), axis=-1) # Convert probabilities to class labels

# precision, recall, F1-score, and FPR for all classes
precision, recall, f1_score, _ = precision_recall_fscore_support(y_test, y_pred, average='micro')
fpr = 1 - recall

# evaluation metrics
print("\nOverall Evaluation:")
print(f"Precision (Micro): {precision:.4f}")
print(f"Recall (Micro): {recall:.4f}")
print(f"F1-Score (Micro): {f1_score:.4f}")
print(f"False Positive Rate (FPR): {fpr:.4f}")

# training time
end_time = time.time()
training_time = end_time - start_time
print("Training time: {:.2f} seconds".format(training_time))

loss, accuracy = model.evaluate(data_padded_test,y_test, verbose=0)
print('Loss:', loss)
print('Accuracy:', accuracy)

from sklearn.metrics import confusion_matrix
import seaborn as sns
from sklearn.metrics import confusion_matrix

# predictions for validation data
predictions = model.predict(data_padded_test)
predicted_labels = np.argmax(predictions, axis=1)

# confusion matrix
cm = confusion_matrix(y_test, predicted_labels)

# print confusion matrix
print("Confusion Matrix:")
print(cm)
plt.figure(figsize=(10, 8))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", xticklabels=encoder.classes_, yticklabels=encoder.classes_)
plt.title("Confusion Matrix")
plt.xlabel("Predicted Label")
plt.ylabel("True Label")
plt.show()

import matplotlib.pyplot as plt
plt.plot(history.history['accuracy'], label='Training Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.title('Training and Validation Accuracy')
plt.legend()
plt.show()

# training and validation loss
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.title('Training and Validation Loss')
plt.legend()
plt.show()

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv1D, MaxPooling1D, Embedding, Flatten, Dense
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
import numpy as np
from tensorflow.keras.initializers import Constant
from sklearn.preprocessing import LabelEncoder
from tensorflow.keras.optimizers import SGD

import time
start_time = time.time()
# Assuming url_df is your DataFrame containing 'Data' and 'Category' columns
url_text = url_df['Data'].tolist()
y = url_df['Category']

# Label encoding for target variable
encoder = LabelEncoder()
y_encoded = encoder.fit_transform(y)

# Custom Tokenizer
tokenizer = Tokenizer(num_words=5000)  # Adjust num_words as needed
tokenizer.fit_on_texts(url_text)
url_sequences = tokenizer.texts_to_sequences(url_text)

# Pad sequences to a fixed length
max_len = 100  # Adjust max_len as needed
url_padded = pad_sequences(url_sequences, maxlen=max_len, padding='post')

data_padded_train, data_padded_test, y_train, y_test = train_test_split(url_padded, y_encoded, test_size=0.2, random_state=42)

# Embedding layer
embedding_dim = 128  # Adjust embedding_dim as needed
embedding_matrix = np.random.rand(len(tokenizer.word_index) + 1, embedding_dim)  # Initialize randomly

# CNN model
model = Sequential()
model.add(Embedding(len(tokenizer.word_index) + 1, embedding_dim, input_length=max_len, embeddings_initializer=Constant(embedding_matrix)))  # Use pre-trained embeddings if available
model.add(Conv1D(32, kernel_size=3, activation='relu'))
model.add(MaxPooling1D(pool_size=2))
model.add(Flatten())
model.add(Dense(128, activation='relu'))
model.add(Dense(len(encoder.classes_), activation='softmax'))  # Output layer with number of classes


# SGD optimizer with momentum
optimizer = SGD(learning_rate=0.01, momentum=0.9)

# Compile with SGD optimizer
model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])
# Train the model
#model.fit(url_padded, y_encoded, epochs=10, batch_size=32, validation_split=0.2)

history = model.fit(data_padded_train, y_train, epochs=10, batch_size=128, validation_split=0.2)
# training time
end_time = time.time()
training_time = end_time - start_time
print("Training time: {:.2f} seconds".format(training_time))

# training and validation accuracy from history

test_start=time.time()
# Evaluate the model on the test set
test_loss, test_accuracy = model.evaluate(data_padded_test, y_test)
test_end=time.time()
test=test_end-test_start
print(f"Test_time: {test:.2f}")
print(f"Test Loss: {test_loss:.4f}")
print(f"Test Accuracy: {test_accuracy:.4f}")

# predictions on test set
y_pred = np.argmax(model.predict(data_padded_test), axis=-1)  # Predict class labels

# precision, recall, F1-score, and FPR for all classes
precision, recall, f1_score, _ = precision_recall_fscore_support(y_test, y_pred, average='micro')
fpr = 1 - recall

# evaluation metrics
print("\nOverall Evaluation:")
print(f"Precision (Micro): {precision:.4f}")
print(f"Recall (Micro): {recall:.4f}")
print(f"F1-Score (Micro): {f1_score:.4f}")
print(f"False Positive Rate (FPR): {fpr:.4f}")



loss, accuracy = model.evaluate(url_padded, y_encoded, verbose=0)
print('Loss:', loss)
print('Accuracy:', accuracy)

from sklearn.metrics import confusion_matrix
import seaborn as sns
from sklearn.metrics import confusion_matrix

# predictions for validation data
predictions = model.predict(data_padded_test)
predicted_labels = np.argmax(predictions, axis=1)

# confusion matrix
cm = confusion_matrix(y_test, predicted_labels)

print("Confusion Matrix:")
print(cm)
plt.figure(figsize=(10, 8))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", xticklabels=encoder.classes_, yticklabels=encoder.classes_)
plt.title("Confusion Matrix")
plt.xlabel("Predicted Label")
plt.ylabel("True Label")
plt.show()

from sklearn.metrics import precision_recall_fscore_support, confusion_matrix
import tensorflow as tf
import matplotlib.pyplot as plt
cm = tf.math.confusion_matrix(y_test, y_pred)

# Normalize confusion matrix for imbalance in classes
# cm = np.around(cm.astype('float') / cm.sum(axis=1)[:, np.newaxis], decimals=2)

plt.figure(figsize=(8, 8))
plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)
plt.colorbar(label='Count')
classes = encoder.classes_  # Get the class labels
fmt = 'd'  # Format specifier for integer values in squares
plt.xticks(np.arange(len(classes)), classes, rotation=45, ha='right')
plt.yticks(np.arange(len(classes)), classes)
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.title('Confusion Matrix')

# heatmap
for i in range(len(cm)):
    for j in range(len(cm[0])):
        plt.text(j, i, format(cm[i, j], fmt), ha="center", va="center", fontsize=10)

plt.grid(False)
plt.tight_layout()
plt.show()

import matplotlib.pyplot as plt
plt.plot(history.history['accuracy'], label='Training Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.title('Training and Validation Accuracy')
plt.legend()
plt.show()

# training and validation loss
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.title('Training and Validation Loss')
plt.legend()
plt.show()

import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, BatchNormalization
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
from sklearn.metrics import precision_recall_fscore_support
from tensorflow.keras.initializers import Constant
import numpy as np
import pandas as pd
import time

# Start recording time
start_time = time.time()


url_df = pd.read_excel(url_dataset_path)
html_df = pd.read_excel(html_dataset_path)

# Extract text data and labels
url_text = url_df['Data'].tolist()
y = url_df['Category']

# Label encoding for target variable
encoder = LabelEncoder()
y_encoded = encoder.fit_transform(y)

# Tokenization
tokenizer = Tokenizer(num_words=5000)
tokenizer.fit_on_texts(url_text)
url_sequences = tokenizer.texts_to_sequences(url_text)

# Padding sequences to a fixed length
max_len = 100
url_padded = pad_sequences(url_sequences, maxlen=max_len, padding='post')

# training and testing sets
data_padded_train, data_padded_test, y_train, y_test = train_test_split(url_padded, y_encoded, test_size=0.2, random_state=42)

# Embedding layer
embedding_dim = 128
embedding_matrix = np.random.rand(len(tokenizer.word_index) + 1, embedding_dim)

# LSTM model
model = Sequential()
model.add(Embedding(len(tokenizer.word_index) + 1, embedding_dim, input_length=max_len, embeddings_initializer=Constant(embedding_matrix)))
model.add(BatchNormalization())  # Add Batch Normalization
model.add(LSTM(128, return_sequences=True))  # First LSTM layer
model.add(Dropout(0.5))  # Add Dropout for regularization
model.add(LSTM(64))  # Second LSTM layer
model.add(Dropout(0.5))  # Add Dropout for regularization
model.add(Dense(128, activation='relu'))  # Dense layer for classification
model.add(Dropout(0.5))  # Add Dropout
model.add(Dense(len(encoder.classes_), activation='softmax'))  # Output layer

# SGD optimizer with momentum
optimizer = tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9)

# Compile
model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])

# Train
history = model.fit(data_padded_train, y_train, epochs=30, batch_size=128, validation_split=0.2)

# training time
end_time = time.time()
training_time = end_time - start_time
print("Training time: {:.2f} seconds".format(training_time))

# Evaluate on test set
test_start = time.time()
test_loss, test_accuracy = model.evaluate(data_padded_test, y_test)
test_end = time.time()
test_duration = test_end - test_start
print(f"Test Time: {test_duration:.2f} seconds")
print(f"Test Loss: {test_loss:.4f}")
print(f"Test Accuracy: {test_accuracy:.4f}")

# test set predictions
y_pred = np.argmax(model.predict(data_padded_test), axis=-1)

# precision, recall, F1-score, and FPR for all classes
precision, recall, f1_score, _ = precision_recall_fscore_support(y_test, y_pred, average='micro')
fpr = 1 - recall

# evaluation metrics
print("\nOverall Evaluation:")
print(f"Precision (Micro): {precision:.4f}")
print(f"Recall (Micro): {recall:.4f}")
print(f"F1-Score (Micro): {f1_score:.4f}")
print(f"False Positive Rate (FPR): {fpr:.4f}")

import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Embedding, SimpleRNN, Dense, Dropout, BatchNormalization
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
from sklearn.metrics import precision_recall_fscore_support
from tensorflow.keras.initializers import Constant
from tensorflow.keras.callbacks import EarlyStopping
import numpy as np
import pandas as pd
import time

# Start recording time
start_time = time.time()

url_df = pd.read_excel(url_dataset_path)

url_text = url_df['Data'].tolist()
y = url_df['Category']

# Label encoding for target variable
encoder = LabelEncoder()
y_encoded = encoder.fit_transform(y)

# Tokenization
tokenizer = Tokenizer(num_words=5000)
tokenizer.fit_on_texts(url_text)
url_sequences = tokenizer.texts_to_sequences(url_text)

# Padding sequences to a fixed length
max_len = 100
url_padded = pad_sequences(url_sequences, maxlen=max_len, padding='post')

# training and testing sets
data_padded_train, data_padded_test, y_train, y_test = train_test_split(url_padded, y_encoded, test_size=0.2, random_state=42)

# Embedding layer configuration
embedding_dim = 128
embedding_matrix = np.random.rand(len(tokenizer.word_index) + 1, embedding_dim)

# RNN model
model = Sequential()
model.add(Embedding(len(tokenizer.word_index) + 1, embedding_dim, input_length=max_len, embeddings_initializer=Constant(embedding_matrix)))
model.add(BatchNormalization())  # Add Batch Normalization
model.add(SimpleRNN(128, return_sequences=True))  # First RNN layer
model.add(Dropout(0.5))  # Add Dropout for regularization
model.add(SimpleRNN(64))  # Second RNN layer
model.add(Dropout(0.5))  # Add Dropout for regularization
model.add(Dense(128, activation='relu'))  # Dense layer for classification
model.add(Dropout(0.5))  # Add Dropout
model.add(Dense(len(encoder.classes_), activation='softmax'))  # Output layer

# SGD optimizer with momentum
optimizer = tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9)
# optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)

# Compile
model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])

# early stopping callback to prevent overfitting
early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)

# Train
history = model.fit(data_padded_train, y_train, epochs=30, batch_size=128, validation_split=0.2, callbacks=[early_stopping])

# training time
end_time = time.time()
training_time = end_time - start_time
print("Training time: {:.2f} seconds".format(training_time))

# Evaluate
test_start = time.time()
test_loss, test_accuracy = model.evaluate(data_padded_test, y_test)
test_end = time.time()
test_duration = test_end - test_start
print(f"Test Time: {test_duration:.2f} seconds")
print(f"Test Loss: {test_loss:.4f}")
print(f"Test Accuracy: {test_accuracy:.4f}")

# predictions on test set
y_pred = np.argmax(model.predict(data_padded_test), axis=-1)

# precision, recall, F1-score, and FPR for all classes
precision, recall, f1_score, _ = precision_recall_fscore_support(y_test, y_pred, average='micro')
fpr = 1 - recall

# evaluation metrics
print("\nOverall Evaluation:")
print(f"Precision (Micro): {precision:.4f}")
print(f"Recall (Micro): {recall:.4f}")
print(f"F1-Score (Micro): {f1_score:.4f}")
print(f"False Positive Rate (FPR): {fpr:.4f}")

import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Embedding, GRU, Dense, Dropout, BatchNormalization
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
from sklearn.metrics import precision_recall_fscore_support
from tensorflow.keras.initializers import Constant
from tensorflow.keras.callbacks import EarlyStopping
import numpy as np
import pandas as pd
import time

# Start recording time
start_time = time.time()


url_df = pd.read_excel(url_dataset_path)

url_text = url_df['Data'].tolist()
y = url_df['Category']

# Label encoding for target variable
encoder = LabelEncoder()
y_encoded = encoder.fit_transform(y)

# Tokenization
tokenizer = Tokenizer(num_words=5000)
tokenizer.fit_on_texts(url_text)
url_sequences = tokenizer.texts_to_sequences(url_text)

# Padding sequences to a fixed length
max_len = 100
url_padded = pad_sequences(url_sequences, maxlen=max_len, padding='post')

# training and testing sets
data_padded_train, data_padded_test, y_train, y_test = train_test_split(url_padded, y_encoded, test_size=0.2, random_state=42)

# Embedding layer configuration
embedding_dim = 128
embedding_matrix = np.random.rand(len(tokenizer.word_index) + 1, embedding_dim)

# GRU model
model = Sequential()
model.add(Embedding(len(tokenizer.word_index) + 1, embedding_dim, input_length=max_len, embeddings_initializer=Constant(embedding_matrix)))
model.add(BatchNormalization())  # Add Batch Normalization
model.add(GRU(128, return_sequences=True))  # First GRU layer
model.add(Dropout(0.5))  # Add Dropout for regularization
model.add(GRU(64))  # Second GRU layer
model.add(Dropout(0.5))  # Add Dropout for regularization
model.add(Dense(128, activation='relu'))  # Dense layer for classification
model.add(Dropout(0.5))  # Add Dropout
model.add(Dense(len(encoder.classes_), activation='softmax'))  # Output layer

# SGD optimizer with momentum
optimizer = tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9)

# Compile
model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])

# early stopping callback
early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)

# Train
history = model.fit(data_padded_train, y_train, epochs=30, batch_size=128, validation_split=0.2, callbacks=[early_stopping])

# training time
end_time = time.time()
training_time = end_time - start_time
print("Training time: {:.2f} seconds".format(training_time))

# Evaluate
test_start = time.time()
test_loss, test_accuracy = model.evaluate(data_padded_test, y_test)
test_end = time.time()
test_duration = test_end - test_start
print(f"Test Time: {test_duration:.2f} seconds")
print(f"Test Loss: {test_loss:.4f}")
print(f"Test Accuracy: {test_accuracy:.4f}")

# predictions on test set
y_pred = np.argmax(model.predict(data_padded_test), axis=-1)

# precision, recall, F1-score, and FPR for all classes
precision, recall, f1_score, _ = precision_recall_fscore_support(y_test, y_pred, average='micro')
fpr = 1 - recall

# evaluation metrics
print("\nOverall Evaluation:")
print(f"Precision (Micro): {precision:.4f}")
print(f"Recall (Micro): {recall:.4f}")
print(f"F1-Score (Micro): {f1_score:.4f}")
print(f"False Positive Rate (FPR): {fpr:.4f}")

import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Embedding, Bidirectional, LSTM, Dense, Dropout, BatchNormalization
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
from sklearn.metrics import precision_recall_fscore_support
from tensorflow.keras.initializers import Constant
from tensorflow.keras.callbacks import EarlyStopping
import numpy as np
import pandas as pd
import time

# Start recording time
start_time = time.time()

url_df = pd.read_excel(url_dataset_path)

url_text = url_df['Data'].tolist()
y = url_df['Category']

# Label encoding for target variable
encoder = LabelEncoder()
y_encoded = encoder.fit_transform(y)

# Tokenization
tokenizer = Tokenizer(num_words=5000)
tokenizer.fit_on_texts(url_text)
url_sequences = tokenizer.texts_to_sequences(url_text)

# Padding sequences to a fixed length
max_len = 100
url_padded = pad_sequences(url_sequences, maxlen=max_len, padding='post')

# training and testing sets
data_padded_train, data_padded_test, y_train, y_test = train_test_split(url_padded, y_encoded, test_size=0.2, random_state=42)

# Embedding layer configuration
embedding_dim = 128
embedding_matrix = np.random.rand(len(tokenizer.word_index) + 1, embedding_dim)

# Bidirectional LSTM
model = Sequential()
model.add(Embedding(len(tokenizer.word_index) + 1, embedding_dim, input_length=max_len, embeddings_initializer=Constant(embedding_matrix)))
model.add(BatchNormalization())  # Add Batch Normalization
model.add(Bidirectional(LSTM(128, return_sequences=True)))  # First Bidirectional LSTM layer
model.add(Dropout(0.5))  # Add Dropout for regularization
model.add(Bidirectional(LSTM(64)))  # Second Bidirectional LSTM layer
model.add(Dropout(0.5))  # Add Dropout for regularization
model.add(Dense(128, activation='relu'))  # Dense layer for classification
model.add(Dropout(0.5))  # Add Dropout
model.add(Dense(len(encoder.classes_), activation='softmax'))  # Output layer

# SGD optimizer with momentum
optimizer = tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9)

# Compile
model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])

# early stopping
early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)

# Train
history = model.fit(data_padded_train, y_train, epochs=30, batch_size=128, validation_split=0.2, callbacks=[early_stopping])

# training time
end_time = time.time()
training_time = end_time - start_time
print("Training time: {:.2f} seconds".format(training_time))

# Evaluate
test_start = time.time()
test_loss, test_accuracy = model.evaluate(data_padded_test, y_test)
test_end = time.time()
test_duration = test_end - test_start
print(f"Test Time: {test_duration:.2f} seconds")
print(f"Test Loss: {test_loss:.4f}")
print(f"Test Accuracy: {test_accuracy:.4f}")

# predictions on test set
y_pred = np.argmax(model.predict(data_padded_test), axis=-1)

# precision, recall, F1-score, and FPR for all classes
precision, recall, f1_score, _ = precision_recall_fscore_support(y_test, y_pred, average='micro')
fpr = 1 - recall

# evaluation metrics
print("\nOverall Evaluation:")
print(f"Precision (Micro): {precision:.4f}")
print(f"Recall (Micro): {recall:.4f}")
print(f"F1-Score (Micro): {f1_score:.4f}")
print(f"False Positive Rate (FPR): {fpr:.4f}")

import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Embedding, Bidirectional, GRU, Dense, Dropout, BatchNormalization
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
from sklearn.metrics import precision_recall_fscore_support
from tensorflow.keras.initializers import Constant
from tensorflow.keras.callbacks import EarlyStopping
import numpy as np
import pandas as pd
import time

# Start recording time
start_time = time.time()

url_df = pd.read_excel(url_dataset_path)

url_text = url_df['Data'].tolist()
y = url_df['Category']

# Label encoding for target variable
encoder = LabelEncoder()
y_encoded = encoder.fit_transform(y)

# Tokenization
tokenizer = Tokenizer(num_words=5000)
tokenizer.fit_on_texts(url_text)
url_sequences = tokenizer.texts_to_sequences(url_text)

# Padding sequences to a fixed length
max_len = 100
url_padded = pad_sequences(url_sequences, maxlen=max_len, padding='post')

# training and testing sets
data_padded_train, data_padded_test, y_train, y_test = train_test_split(url_padded, y_encoded, test_size=0.2, random_state=42)

# Embedding layer configuration
embedding_dim = 128
embedding_matrix = np.random.rand(len(tokenizer.word_index) + 1, embedding_dim)

# Bidirectional GRU
model = Sequential()
model.add(Embedding(len(tokenizer.word_index) + 1, embedding_dim, input_length=max_len, embeddings_initializer=Constant(embedding_matrix)))
model.add(BatchNormalization())  # Add Batch Normalization
model.add(Bidirectional(GRU(128, return_sequences=True)))  # First Bidirectional GRU layer
model.add(Dropout(0.5))  # Add Dropout for regularization
model.add(Bidirectional(GRU(64)))  # Second Bidirectional GRU layer
model.add(Dropout(0.5))  # Add Dropout for regularization
model.add(Dense(128, activation='relu'))  # Dense layer for classification
model.add(Dropout(0.5))  # Add Dropout
model.add(Dense(len(encoder.classes_), activation='softmax'))  # Output layer

# SGD optimizer with momentum
optimizer = tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9)

# Compile
model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])

# early stopping callback
early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)

# Train
history = model.fit(data_padded_train, y_train, epochs=30, batch_size=128, validation_split=0.2, callbacks=[early_stopping])

# training time
end_time = time.time()
training_time = end_time - start_time
print("Training time: {:.2f} seconds".format(training_time))

# Evaluate
test_start = time.time()
test_loss, test_accuracy = model.evaluate(data_padded_test, y_test)
test_end = time.time()
test_duration = test_end - test_start
print(f"Test Time: {test_duration:.2f} seconds")
print(f"Test Loss: {test_loss:.4f}")
print(f"Test Accuracy: {test_accuracy:.4f}")

# predictions on test set
y_pred = np.argmax(model.predict(data_padded_test), axis=-1)

# precision, recall, F1-score, and FPR for all classes
precision, recall, f1_score, _ = precision_recall_fscore_support(y_test, y_pred, average='micro')
fpr = 1 - recall

# evaluation metrics
print("\nOverall Evaluation:")
print(f"Precision (Micro): {precision:.4f}")
print(f"Recall (Micro): {recall:.4f}")
print(f"F1-Score (Micro): {f1_score:.4f}")
print(f"False Positive Rate (FPR): {fpr:.4f}")

import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Embedding, Dense, Dropout, BatchNormalization, Flatten
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
from sklearn.metrics import precision_recall_fscore_support
from tensorflow.keras.initializers import Constant
from tensorflow.keras.callbacks import EarlyStopping
import numpy as np
import pandas as pd
import time

# recording time
start_time = time.time()

url_df = pd.read_excel(url_dataset_path)

# text data and labels
url_text = url_df['Data'].tolist()
y = url_df['Category']

# Label encoding
encoder = LabelEncoder()
y_encoded = encoder.fit_transform(y)

# Tokenization
tokenizer = Tokenizer(num_words=5000)
tokenizer.fit_on_texts(url_text)
url_sequences = tokenizer.texts_to_sequences(url_text)

# Padding sequences to a fixed length
max_len = 100
url_padded = pad_sequences(url_sequences, maxlen=max_len, padding='post')

# training and testing sets
data_padded_train, data_padded_test, y_train, y_test = train_test_split(url_padded, y_encoded, test_size=0.2, random_state=42)

# Embedding layer configuration
embedding_dim = 128
embedding_matrix = np.random.rand(len(tokenizer.word_index) + 1, embedding_dim)

# ANN model
model = Sequential()
model.add(Embedding(len(tokenizer.word_index) + 1, embedding_dim, input_length=max_len, embeddings_initializer=Constant(embedding_matrix)))
model.add(Flatten())  # Flatten the input from the embedding layer
model.add(BatchNormalization())  # Add Batch Normalization
model.add(Dense(256, activation='relu'))  # First fully connected layer
model.add(Dropout(0.5))  # Add Dropout for regularization
model.add(Dense(128, activation='relu'))  # Second fully connected layer
model.add(Dropout(0.5))  # Add Dropout for regularization
model.add(Dense(64, activation='relu'))  # Third fully connected layer
model.add(Dropout(0.5))  # Add Dropout for regularization
model.add(Dense(len(encoder.classes_), activation='softmax'))  # Output layer

# SGD optimizer with momentum
optimizer = tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9)

# Compile
model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])

# early stopping
early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)

# Train
history = model.fit(data_padded_train, y_train, epochs=30, batch_size=128, validation_split=0.2, callbacks=[early_stopping])

# training time
end_time = time.time()
training_time = end_time - start_time
print("Training time: {:.2f} seconds".format(training_time))

# Evaluate
test_start = time.time()
test_loss, test_accuracy = model.evaluate(data_padded_test, y_test)
test_end = time.time()
test_duration = test_end - test_start
print(f"Test Time: {test_duration:.2f} seconds")
print(f"Test Loss: {test_loss:.4f}")
print(f"Test Accuracy: {test_accuracy:.4f}")

# predictions on test set
y_pred = np.argmax(model.predict(data_padded_test), axis=-1)

# precision, recall, F1-score, and FPR for all classes
precision, recall, f1_score, _ = precision_recall_fscore_support(y_test, y_pred, average='micro')
fpr = 1 - recall

# evaluation metrics
print("\nOverall Evaluation:")
print(f"Precision (Micro): {precision:.4f}")
print(f"Recall (Micro): {recall:.4f}")
print(f"F1-Score (Micro): {f1_score:.4f}")
print(f"False Positive Rate (FPR): {fpr:.4f}")

"""## Bert Model for classification"""

!pip install transformers

import tensorflow as tf
from transformers import BertTokenizer, TFBertForSequenceClassification, create_optimizer
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
from sklearn.metrics import precision_recall_fscore_support
import pandas as pd
import time


url_df = pd.read_excel(url_dataset_path)

# Extract text data and labels
url_text = url_df['Data'].tolist()
y = url_df['Category']

# Label encoding for target variable
encoder = LabelEncoder()
y_encoded = encoder.fit_transform(y)

# Load pre-trained BERT tokenizer and model
model_name = 'bert-base-uncased'  # You can choose a different BERT variant
tokenizer = BertTokenizer.from_pretrained(model_name)
model = TFBertForSequenceClassification.from_pretrained(model_name, num_labels=len(encoder.classes_))

# Tokenize the text data
input_ids = []
attention_masks = []
for text in url_text:
    encoded_dict = tokenizer.encode_plus(
        text,
        add_special_tokens=True,
        max_length=128,  # Make sure this is consistent
        padding='max_length',
        truncation=True,  # Add truncation to handle long sequences
        return_attention_mask=True,
        return_tensors='tf'
    )
    input_ids.append(encoded_dict['input_ids'])
    attention_masks.append(encoded_dict['attention_mask'])

# Convert lists to tensors and then to NumPy arrays
input_ids = tf.concat(input_ids, axis=0).numpy() # Convert to NumPy array
attention_masks = tf.concat(attention_masks, axis=0).numpy() # Convert to NumPy array


# training and testing sets
ids_train, ids_test, masks_train, masks_test, y_train, y_test = train_test_split(
    input_ids, attention_masks, y_encoded, test_size=0.2, random_state=42
)

# optimizer, loss function, metrics
num_train_steps = len(ids_train) // 32 * 3 # Assuming batch_size=32 and 3 epochs
optimizer, schedule = create_optimizer(
    init_lr=2e-5, num_warmup_steps=0, num_train_steps=num_train_steps
)

loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)
metrics = ['accuracy']

# Compile
model.compile(optimizer=optimizer, loss=loss, metrics=metrics)

# Train
history = model.fit(
    x={'input_ids': ids_train, 'attention_mask': masks_train},
    y=y_train,
    epochs=3,  # Adjust as needed
    batch_size=32,  # Adjust as needed
    validation_split=0.2
)

# Evaluate
test_start = time.time()
test_loss, test_accuracy = model.evaluate(
    x={'input_ids': ids_test, 'attention_mask': masks_test},
    y=y_test
)
test_end = time.time()
test_duration = test_end - test_start
print(f"Test Time: {test_duration:.2f} seconds")
print(f"Test Loss: {test_loss:.4f}")
print(f"Test Accuracy: {test_accuracy:.4f}")

# predictions on test set
predictions = model.predict(x={'input_ids': ids_test, 'attention_mask': masks_test})
y_pred = np.argmax(predictions.logits, axis=1)

# precision, recall, F1-score, and FPR for all classes
precision, recall, f1_score, _ = precision_recall_fscore_support(y_test, y_pred, average='micro')
fpr = 1 - recall

# evaluation metrics
print("\nOverall Evaluation:")
print(f"Precision (Micro): {precision:.4f}")
print(f"Recall (Micro): {recall:.4f}")
print(f"F1-Score (Micro): {f1_score:.4f}")
print(f"False Positive Rate (FPR): {fpr:.4f}")

"""### Save model in drive"""

from google.colab import drive
drive.mount('/content/drive')

save_path = '/content/drive/MyDrive/TrainedModels/nishant_url_bert'  # Replace with your desired path in Google Drive
model.save_pretrained(save_path)

tokenizer = BertTokenizer.from_pretrained('bert-base-uncased') # Replace 'bert-base-uncased' with your desired model
tokenizer.save_pretrained(save_path)

"""### Use the pretrained model"""

tokenizer = BertTokenizer.from_pretrained(save_path)
model = TFBertForSequenceClassification.from_pretrained(save_path)

text = "www.nikeshthapa.com"  # Replace with the text you want to classify
inputs = tokenizer(text, return_tensors="tf")

outputs = model(**inputs)
predicted_class = tf.math.argmax(outputs.logits, axis=1).numpy()
print('predicted_class:', encoder.inverse_transform(predicted_class))
